{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2bd14b89",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'matplotlib'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mplt\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mos\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# ===== Cáº¤U HÃŒNH =====\u001b[39;00m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'matplotlib'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "# ===== Cáº¤U HÃŒNH =====\n",
    "project_root = os.path.dirname(os.getcwd())\n",
    "preproc_dir = os.path.join(project_root, \"pre_processing\")\n",
    "X_path = os.path.join(preproc_dir, \"X_data.npy\")\n",
    "y_path = os.path.join(preproc_dir, \"y_data.npy\")\n",
    "\n",
    "# ===== Xá»¬ LÃ =====\n",
    "\n",
    "\n",
    "# 1. Load dá»¯ liá»‡u\n",
    "y_onehot = np.load(y_path)\n",
    "classes = np.load(os.path.join(preproc_dir, \"classes.npy\"))\n",
    "\n",
    "# 2. Giáº£i mÃ£ One-hot vá» dáº¡ng sá»‘ nguyÃªn (Index)\n",
    "# VÃ­ dá»¥: [0, 0, 1, 0, 0] -> Index 2\n",
    "y_indices = np.argmax(y_onehot, axis=1)\n",
    "\n",
    "# 3. Äáº¿m sá»‘ lÆ°á»£ng\n",
    "unique, counts = np.unique(y_indices, return_counts=True)\n",
    "stats = dict(zip(unique, counts))\n",
    "\n",
    "total_samples = len(y_indices)\n",
    "\n",
    "# ===== IN Káº¾T QUáº¢ =====\n",
    "print(\"\\n\" + \"=\"*40)\n",
    "print(f\"ğŸ“Š BÃO CÃO THá»NG KÃŠ Dá»® LIá»†U ({total_samples} máº«u)\")\n",
    "print(\"=\"*40)\n",
    "print(f\"{'NHÃƒN (LABEL)':<15} | {'Sá» LÆ¯á»¢NG':<10} | {'Tá»¶ Lá»† %':<10}\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "counts_list = [] # Äá»ƒ váº½ biá»ƒu Ä‘á»“\n",
    "\n",
    "for i, class_name in enumerate(classes):\n",
    "    count = stats.get(i, 0) # Láº¥y sá»‘ lÆ°á»£ng, náº¿u khÃ´ng cÃ³ thÃ¬ báº±ng 0\n",
    "    percent = (count / total_samples) * 100\n",
    "    counts_list.append(count)\n",
    "    \n",
    "    print(f\"{class_name:<15} | {count:<10} | {percent:.1f}%\")\n",
    "\n",
    "print(\"-\" * 40)\n",
    "\n",
    "# ===== Váº¼ BIá»‚U Äá»’ (Náº¿u cháº¡y trÃªn mÃ¡y tÃ­nh cÃ³ mÃ n hÃ¬nh) =====\n",
    "try:\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    bars = plt.bar(classes, counts_list, color=['#ff9999','#66b3ff','#99ff99','#ffcc99', '#c2c2f0'])\n",
    "    \n",
    "    # Viáº¿t sá»‘ lÃªn Ä‘áº§u cá»™t\n",
    "    for bar in bars:\n",
    "        yval = bar.get_height()\n",
    "        plt.text(bar.get_x() + bar.get_width()/2, yval + 1, int(yval), ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "    plt.title('PhÃ¢n bá»‘ dá»¯ liá»‡u cáº£m xÃºc', fontsize=16)\n",
    "    plt.xlabel('Cáº£m xÃºc', fontsize=12)\n",
    "    plt.ylabel('Sá»‘ lÆ°á»£ng file', fontsize=12)\n",
    "    plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "    plt.show()\n",
    "    print(\" ÄÃ£ váº½ biá»ƒu Ä‘á»“ phÃ¢n bá»‘.\")\n",
    "except Exception as e:\n",
    "    print(\" KhÃ´ng thá»ƒ váº½ biá»ƒu Ä‘á»“ (cÃ³ thá»ƒ do mÃ´i trÆ°á»ng dÃ²ng lá»‡nh).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2c2259c4",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtf\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodel_selection\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmetrics\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m classification_report, confusion_matrix\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, Conv1D, MaxPooling1D, BatchNormalization\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# Táº¯t log rÃ¡c cá»§a Tensorflow\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "\n",
    "# ===== 1. LOAD Dá»® LIá»†U =====\n",
    "print(\"â³ Äang load dá»¯ liá»‡u...\")\n",
    "\n",
    "# XÃ¡c Ä‘á»‹nh Ä‘Æ°á»ng dáº«n Ä‘Ãºng tá»›i thÆ° má»¥c pre_processing (náº±m cáº¡nh TrainModel)\n",
    "project_root = os.path.dirname(os.getcwd())\n",
    "preproc_dir = os.path.join(project_root, \"pre_processing\")\n",
    "X_path = os.path.join(preproc_dir, \"X_data.npy\")\n",
    "y_path = os.path.join(preproc_dir, \"y_data.npy\")\n",
    "classes_path = os.path.join(preproc_dir, \"classes.npy\")\n",
    "\n",
    "missing = [p for p in [X_path, y_path, classes_path] if not os.path.exists(p)]\n",
    "if missing:\n",
    "    print(\"âŒ Lá»–I: KhÃ´ng tÃ¬m tháº¥y cÃ¡c file .npy sau:\")\n",
    "    for p in missing:\n",
    "        print(f\" - {p}\")\n",
    "    print(\"ğŸ‘‰ HÃ£y Ä‘áº£m báº£o notebook Ä‘ang cháº¡y tá»« thÆ° má»¥c TrainModel, vÃ  thÆ° má»¥c pre_processing náº±m á»Ÿ cÃ¹ng cáº¥p vá»›i TrainModel.\")\n",
    "    raise SystemExit(1)\n",
    "\n",
    "# Load dá»¯ liá»‡u\n",
    "X = np.load(X_path)\n",
    "y = np.load(y_path)\n",
    "classes = np.load(classes_path)\n",
    "\n",
    "print(f\"âœ… Dá»¯ liá»‡u input: {X.shape}\")  # (88, 130, 13)\n",
    "print(f\"âœ… Sá»‘ lá»›p cáº£m xÃºc: {len(classes)} {classes}\")\n",
    "\n",
    "# Chia táº­p Train (80%) vÃ  Test (20%)\n",
    "# VÃ¬ dá»¯ liá»‡u Ã­t (88 máº«u), ta Ä‘á»ƒ test_size nhá» thÃ´i Ä‘á»ƒ dÃ nh dá»¯ liá»‡u cho mÃ¡y há»c\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# ===== 2. THIáº¾T Káº¾ MODEL (CNN 1D) =====\n",
    "input_shape = (X.shape[1], X.shape[2])  # (130, 13)\n",
    "num_classes = y.shape[1]\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "# Block 1\n",
    "model.add(Conv1D(64, kernel_size=3, activation='relu', input_shape=input_shape))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "\n",
    "# Block 2\n",
    "model.add(Conv1D(128, kernel_size=3, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "\n",
    "# Block 3\n",
    "model.add(Conv1D(64, kernel_size=3, activation='relu'))  # Giáº£m filter chÃºt vÃ¬ data Ã­t\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "# Fully Connected\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.3))  # Dropout giÃºp giáº£m há»c váº¹t\n",
    "model.add(Dense(num_classes, activation='softmax'))  # Output layer\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# ===== 3. TRAINING =====\n",
    "print(\"\\nğŸš€ Báº®T Äáº¦U TRAIN...\")\n",
    "# Batch size nhá» (8 hoáº·c 16) vÃ¬ tá»•ng dá»¯ liá»‡u chá»‰ cÃ³ 88 máº«u\n",
    "history = model.fit(X_train, y_train,\n",
    "                    epochs=50,\n",
    "                    batch_size=8,\n",
    "                    validation_data=(X_test, y_test),\n",
    "                    verbose=1)\n",
    "\n",
    "# ===== 4. ÄÃNH GIÃ =====\n",
    "print(\"\\nğŸ“Š ÄÃNH GIÃ Káº¾T QUáº¢ TRÃŠN Táº¬P TEST:\")\n",
    "loss, acc = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(f\"ğŸ¯ Äá»™ chÃ­nh xÃ¡c (Accuracy): {acc*100:.2f}%\")\n",
    "\n",
    "# BÃ¡o cÃ¡o chi tiáº¿t\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "y_true = np.argmax(y_test, axis=1)\n",
    "\n",
    "print(\"\\n--- CHI TIáº¾T Tá»ªNG Lá»šP ---\")\n",
    "print(classification_report(y_true, y_pred_classes, target_names=classes))\n",
    "\n",
    "# ===== 5. LÆ¯U MODEL =====\n",
    "model_name = \"emotion_model.keras\"  # ÄuÃ´i má»›i cá»§a Keras lÃ  .keras (thay vÃ¬ .h5)\n",
    "model.save(model_name)\n",
    "print(f\"\\nğŸ’¾ ÄÃ£ lÆ°u model táº¡i: {model_name}\")\n",
    "print(\"ğŸ‘‰ BÃ¢y giá» báº¡n cÃ³ thá»ƒ dÃ¹ng file nÃ y Ä‘á»ƒ dá»± Ä‘oÃ¡n cáº£m xÃºc!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f598420b",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'librosa'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlibrosa\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtf\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mos\u001b[39;00m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'librosa'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import librosa\n",
    "import tensorflow as tf\n",
    "import os\n",
    "\n",
    "# ===== Cáº¤U HÃŒNH =====\n",
    "# ÄÆ°á»ng dáº«n Ä‘áº¿n file audio báº¡n muá»‘n thá»­\n",
    "# Báº¡n cÃ³ thá»ƒ Ä‘á»•i tÃªn file nÃ y thÃ nh file báº¥t ká»³ báº¡n muá»‘n test\n",
    "TEST_FILE = r\"E:\\KHMT\\N4K2\\DATN\\data\\raw_cuts_with_time_VNDC\\0h01m55s_seg0022.wav\" \n",
    "\n",
    "MODEL_PATH = \"emotion_model.keras\"\n",
    "# Äáº£m báº£o load Ä‘Ãºng 'classes.npy' tá»« thÆ° má»¥c pre_processing (cÃ¹ng cáº¥p vá»›i TrainModel)\n",
    "project_root = os.path.dirname(os.getcwd())\n",
    "CLASSES_PATH = os.path.join(project_root, \"pre_processing\", \"classes.npy\")\n",
    "\n",
    "SAMPLE_RATE = 22050\n",
    "DURATION = 3\n",
    "SAMPLES_PER_TRACK = SAMPLE_RATE * DURATION\n",
    "\n",
    "# ===== HÃ€M Xá»¬ LÃ (Pháº£i giá»‘ng há»‡t lÃºc train) =====\n",
    "def extract_mfcc(file_path):\n",
    "    try:\n",
    "        signal, sr = librosa.load(file_path, sr=SAMPLE_RATE)\n",
    "        if len(signal) > SAMPLES_PER_TRACK:\n",
    "            signal = signal[:SAMPLES_PER_TRACK]\n",
    "        else:\n",
    "            padding = int(SAMPLES_PER_TRACK - len(signal))\n",
    "            signal = np.pad(signal, (0, padding), mode='constant')\n",
    "        mfcc = librosa.feature.mfcc(y=signal, sr=sr, n_mfcc=13, n_fft=2048, hop_length=512)\n",
    "        return mfcc.T\n",
    "    except Exception as e:\n",
    "        print(f\"Lá»—i Ä‘á»c file: {e}\")\n",
    "        return None\n",
    "\n",
    "# ===== CHÆ¯Æ NG TRÃŒNH Dá»° ÄOÃN =====\n",
    "# 1. Load Model vÃ  NhÃ£n\n",
    "print(\"â³ Äang load model...\")\n",
    "model = tf.keras.models.load_model(MODEL_PATH)\n",
    "classes = np.load(CLASSES_PATH)\n",
    "print(f\"âœ… ÄÃ£ load model. CÃ¡c nhÃ£n AI biáº¿t: {classes}\")\n",
    "\n",
    "# 2. Xá»­ lÃ½ file Ã¢m thanh\n",
    "print(f\"ğŸ§ Äang nghe file: {os.path.basename(TEST_FILE)}\")\n",
    "mfcc = extract_mfcc(TEST_FILE)\n",
    "\n",
    "if mfcc is not None:\n",
    "    # Model cáº§n input dáº¡ng (Sá»‘ lÆ°á»£ng, Thá»i gian, Äáº·c trÆ°ng) -> (1, 130, 13)\n",
    "    mfcc = np.expand_dims(mfcc, axis=0) \n",
    "\n",
    "    # 3. Dá»± Ä‘oÃ¡n\n",
    "    prediction = model.predict(mfcc)\n",
    "    predicted_index = np.argmax(prediction)\n",
    "    predicted_label = classes[predicted_index]\n",
    "    confidence = np.max(prediction) * 100 # Äá»™ tin cáº­y\n",
    "\n",
    "    print(\"\\n\" + \"=\"*30)\n",
    "    print(f\"ğŸ¤– Káº¾T QUáº¢ Dá»° ÄOÃN: {predicted_label}\")\n",
    "    print(f\"ğŸ¯ Äá»™ tin cáº­y: {confidence:.2f}%\")\n",
    "    print(\"=\"*30)\n",
    "    \n",
    "    # In ra xÃ¡c suáº¥t cá»§a tá»«ng nhÃ£n\n",
    "    print(\"\\nChi tiáº¿t xÃ¡c suáº¥t:\")\n",
    "    for i, label in enumerate(classes):\n",
    "        print(f\"- {label}: {prediction[0][i]*100:.2f}%\")\n",
    "\n",
    "else:\n",
    "    print(\"âŒ KhÃ´ng xá»­ lÃ½ Ä‘Æ°á»£c file Ã¢m thanh.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
